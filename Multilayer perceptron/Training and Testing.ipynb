{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "sLvjgI5o8FMb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('processed-penguins.csv')"
      ],
      "metadata": {
        "id": "Wb-Lk8x-8Nil"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XuL7Ia458dC4",
        "outputId": "79ae4759-644b-4f84-a878-f3adbd87afb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       species  bill_length_mm  bill_depth_mm  flipper_length_mm  gender  \\\n",
              "0       Adelie           0.391          0.187              0.181       0   \n",
              "1       Adelie           0.395          0.174              0.186       1   \n",
              "2       Adelie           0.403          0.180              0.195       1   \n",
              "3       Adelie           0.396          0.177              0.186       1   \n",
              "4       Adelie           0.367          0.193              0.193       1   \n",
              "..         ...             ...            ...                ...     ...   \n",
              "145  Chinstrap           0.508          0.185              0.201       0   \n",
              "146  Chinstrap           0.501          0.179              0.190       1   \n",
              "147  Chinstrap           0.490          0.196              0.212       0   \n",
              "148  Chinstrap           0.515          0.187              0.187       0   \n",
              "149  Chinstrap           0.498          0.173              0.198       1   \n",
              "\n",
              "     body_mass_g  \n",
              "0         0.3750  \n",
              "1         0.3800  \n",
              "2         0.3250  \n",
              "3         0.3500  \n",
              "4         0.3450  \n",
              "..           ...  \n",
              "145       0.4450  \n",
              "146       0.3400  \n",
              "147       0.4300  \n",
              "148       0.3250  \n",
              "149       0.3675  \n",
              "\n",
              "[150 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ff608bf-a345-4b0f-9e7a-32d46f59a4a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>gender</th>\n",
              "      <th>body_mass_g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>0.391</td>\n",
              "      <td>0.187</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>0.395</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.186</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>0.396</td>\n",
              "      <td>0.177</td>\n",
              "      <td>0.186</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>0.367</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.193</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>0.508</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>0.501</td>\n",
              "      <td>0.179</td>\n",
              "      <td>0.190</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.212</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.187</td>\n",
              "      <td>0.187</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Chinstrap</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.173</td>\n",
              "      <td>0.198</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ff608bf-a345-4b0f-9e7a-32d46f59a4a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ff608bf-a345-4b0f-9e7a-32d46f59a4a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ff608bf-a345-4b0f-9e7a-32d46f59a4a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Test_Dataframes ():\n",
        "    \n",
        "    df_train = dataset.sample(frac=0.6,random_state=1) \n",
        "    df_test = dataset.loc[~dataset.index.isin(df_train.index)]\n",
        "    \n",
        "    X_train = df_train.drop(['species'], axis=1)\n",
        "    X_test  = df_test.drop(['species'], axis=1)\n",
        "    \n",
        "    Y_train = pd.get_dummies(df_train.species)\n",
        "    Y_test = pd.get_dummies(df_test.species)\n",
        "    \n",
        "    return X_train, Y_train,X_test, Y_test"
      ],
      "metadata": {
        "id": "TiWWG7g08NlP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train,X_test, Y_test = Train_Test_Dataframes()"
      ],
      "metadata": {
        "id": "TW2XEKOi8Nn5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqHHcB7NmY47",
        "outputId": "4ffc9649-a6f8-4682-8731-0a0f7a0262ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 5)\n",
            "(90, 3)\n",
            "(60, 5)\n",
            "(60, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "  def __init__(self, num_layers, num_neurons, add_bias, activation_fun, eta=0.01, epochs=1000):\n",
        "    self.lr = eta\n",
        "    self.epochs = epochs\n",
        "    self.activation_function = activation_fun\n",
        "    self.weights = None\n",
        "    self.add_bias = add_bias\n",
        "    self.layers = num_layers\n",
        "    self.neurons = num_neurons\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "  def der_sigmoid(self, sigmoid):\n",
        "    return sigmoid * (1 - sigmoid) \n",
        "\n",
        "  def tanh(self, x):\n",
        "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
        "\n",
        "  def der_tanh(self, tanh):\n",
        "    return 1 - (tanh * tanh)\n",
        "\n",
        "\n",
        "  def initialize_weights(self, L, architecture_layers,f_bias):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    L == num of layers\n",
        "    architecture_layers == list containing the dimensions of each layer in our deep neural network\n",
        "    f_bias == flag for bias\n",
        "\n",
        "    Returns:\n",
        "    weights == python dictionary containing (\"W1\", \"b1\", ..., \"WL\", \"bL\")\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(0)\n",
        "    weights = {}\n",
        "\n",
        "    for l in range(1, L):\n",
        "        \n",
        "        weights['W' + str(l)] = np.random.randn(architecture_layers[l],architecture_layers[l-1]) \n",
        "        \n",
        "        if f_bias:\n",
        "          weights['b' + str(l)] = np.zeros((architecture_layers[l],1))\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "\n",
        "  def forward_propagation(self, L, X, parameters, activation, f_bias):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    L == num of layers\n",
        "    X == array of shape (n,1)\n",
        "    parameters == dict of initialize_weights\n",
        "    activation == activation function (sigmoid) or (tanh)\n",
        "    f_bias == flag for bias\n",
        "\n",
        "    \n",
        "    Returns:\n",
        "    Activaions == dict containing the result of activation functions of each layer in our deep neural network\n",
        "    \"\"\"\n",
        "\n",
        "    Activaions = {}\n",
        "    A = X\n",
        "    Activaions['F' + str(0)] = A\n",
        "\n",
        "    for l in range(1, L):\n",
        "      A_prev = A\n",
        "\n",
        "      Z = np.dot(parameters['W' + str(l)],A_prev)\n",
        "      \n",
        "      if f_bias:\n",
        "        Z += parameters['b' + str(l)]\n",
        "\n",
        "      if activation == \"sigmoid\": \n",
        "        A = self.sigmoid(Z)\n",
        "      elif activation == \"tanh\":\n",
        "        A = self.tanh(Z)\n",
        "\n",
        "      Activaions['F' + str(l)] = A\n",
        "\n",
        "    return Activaions\n",
        "\n",
        "\n",
        "  def backward_propagation(self, L, X, Y, parameters, activation, Activaions):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    L == num of layers\n",
        "    X == array of shape (n,1)\n",
        "    Y == Actual value (3,1)\n",
        "    activation == activation function (sigmoid) or (tanh)\n",
        "    Activaions == dict of activation values for each layer\n",
        "    parameters == dict of initialize_weights\n",
        "    \n",
        "    Returns:\n",
        "    gradients == dict containing the result of gradients for each layer in our deep neural network\n",
        "    \"\"\"\n",
        "\n",
        "    gradients = {}\n",
        "    Error = Y - Activaions['F' + str(L-1)]\n",
        "    \n",
        "    if activation == \"sigmoid\": \n",
        "      gradients['G' + str(L-1)] = Error * self.der_sigmoid(Activaions['F' + str(L-1)]) #(3,1)\n",
        "    elif activation == \"tanh\":\n",
        "      gradients['G' + str(L-1)] = Error * self.der_tanh(Activaions['F' + str(L-1)])\n",
        "    \n",
        "    for l in reversed(range(1, L-1)): \n",
        "      \n",
        "      if activation == \"sigmoid\": \n",
        "        gradients['G' + str(l)] = np.dot(parameters['W' + str(l+1)].T, gradients['G' + str(l+1)]) * self.der_sigmoid(Activaions['F' + str(l)]) \n",
        "      elif activation == \"tanh\":\n",
        "        gradients['G' + str(l)] = np.dot(parameters['W' + str(l+1)].T, gradients['G' + str(l+1)]) * self.der_tanh(Activaions['F' + str(l)])\n",
        "            \n",
        "    return gradients\n",
        "\n",
        "\n",
        "\n",
        "  def update_parameters(self, L, Activaions, parameters, gradients, eta, f_bias):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    L == num of layers\n",
        "    eta == learning rate\n",
        "    f_bias == flag for bias\n",
        "    Activaions == dict of activation values for each layer\n",
        "    parameters == dict of initialize_weights\n",
        "    gradients == dict containing the result of gradients for each layer in our deep neural network\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "    \"\"\"\n",
        "\n",
        "    for l in range(1, L):\n",
        "      parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] + eta * np.dot(gradients[\"G\" + str(l)] , Activaions['F' + str(l-1)].T)\n",
        "      \n",
        "      if f_bias:\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] + eta * gradients[\"G\" + str(l)]\n",
        "  \n",
        "    return parameters\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, L, X, parameters, activation, f_bias, prediction):\n",
        "    \n",
        "    A = X\n",
        "\n",
        "    for l in range(1, L):\n",
        "      A_prev = A\n",
        "\n",
        "      Z = np.dot(parameters['W' + str(l)],A_prev) #Z(l,1)\n",
        "      \n",
        "      if f_bias:\n",
        "        Z += parameters['b' + str(l)]\n",
        "\n",
        "      if activation == \"sigmoid\": \n",
        "        A = self.sigmoid(Z)\n",
        "      elif activation == \"tanh\":\n",
        "        A = self.tanh(Z)\n",
        "    \n",
        "    Max_value = A.max()\n",
        "    y_predicted = [0 if i < Max_value else 1 for i in A]\n",
        "    prediction.append(y_predicted)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, X,Y):\n",
        "    \n",
        "    self.weights = self.initialize_weights(self.layers, self.neurons, self.add_bias)\n",
        "\n",
        "    y = Y.to_numpy()\n",
        "    x = X.to_numpy()\n",
        "    \n",
        "    for _ in range(self.epochs):\n",
        "        for indx, x_i in enumerate(x):\n",
        "          x_i = x_i.reshape((len(x_i),1))\n",
        "          y_i = y[indx]\n",
        "          y_i = y_i.reshape((len(y_i),1))\n",
        "          \n",
        "          Activaions = self.forward_propagation(self.layers, x_i, self.weights, self.activation_function, self.add_bias)\n",
        "          gradients  = self.backward_propagation(self.layers, x_i, y_i, self.weights, self.activation_function, Activaions)\n",
        "          self.weights = self.update_parameters(self.layers, Activaions, self.weights, gradients, self.lr, self.add_bias)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    x = X.to_numpy()\n",
        "    prediction = []\n",
        "    \n",
        "    for x_i in x:\n",
        "      x_i = x_i.reshape((len(x_i),1))\n",
        "      self.forward(self.layers, x_i, self.weights, self.activation_function, self.add_bias, prediction)\n",
        "      \n",
        "    return prediction"
      ],
      "metadata": {
        "id": "yfY8uADfCJde"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_func(a):\n",
        "  return (a[0] & a[1] & a[2])\n",
        "\n",
        "def arg_max_value_func(a):\n",
        "  index = ['Adelie','Chinstrap','Gentoo']\n",
        "  if a[0] == 1:\n",
        "    return index[0]\n",
        "  if a[1] == 1:\n",
        "    return index[1]\n",
        "  if a[2] == 1:\n",
        "    return index[2]"
      ],
      "metadata": {
        "id": "sz94HBfFJAif"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_predict):\n",
        "  l = (predictions == y)\n",
        "  l = np.apply_along_axis(my_func, 1, l)\n",
        "  \n",
        "  acccuray= np.sum(l == True) / len(y_true)\n",
        "  return acccuray"
      ],
      "metadata": {
        "id": "CDlMaHD8IS0Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ConfusionMatrix(y_test, predictions, class_1, class_2, class_3):\n",
        "  cm = confusion_matrix(y_test, predictions)\n",
        "  cm_df = pd.DataFrame(cm,index = [class_1,class_2,class_3], \n",
        "                          columns = [class_1,class_2,class_3])\n",
        "  plt.figure(figsize=(6,6))\n",
        "  sns.heatmap(cm_df, annot=True)\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.ylabel('Actal Values')\n",
        "  plt.xlabel('Predicted Values')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "yjSatAZAg1-Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Enter number of hidden layers: \")\n",
        "# L = int(input())\n",
        "\n",
        "# print(\"Enter number of neurons in each hidden layers: \")\n",
        "# neurons = [5]\n",
        "\n",
        "# for i in range(L):\n",
        "#   n = int(input())\n",
        "#   neurons.append(n)\n",
        "\n",
        "# neurons.append(3)\n",
        "# L += 2\n",
        "\n",
        "# print(\"Enter learning rate (eta): \")\n",
        "# Lr = float(input())\n",
        "\n",
        "# print(\"Enter number of epochs: \")\n",
        "# epochs = int(input())\n",
        "\n",
        "# print(\"Add bias or not (True=1 / False=0): \")\n",
        "# bias = int(input())\n",
        "\n",
        "# print(\"choose to use (Sigmoid / Tanh) as the activation function: \")\n",
        "# act_fun = input()\n",
        "\n",
        "'''\n",
        "3 - [5,4,3] - True  - \"sigmoid\" - 0.1 - 500   --> (98)\n",
        "3 - [5,4,3] - False - \"sigmoid\" - 0.1 - 500   --> (100)\n",
        "\n",
        "3 , [5,4,3] , True , \"tanh\" , 0.01 , 500 --> (98)\n",
        "3 , [5,4,3] , False , \"tanh\" , 0.01 , 500 --> (100)\n",
        "'''\n",
        "# p = MLP(L, neurons, bias, act_fun, Lr, epochs)\n",
        "\n",
        "p = MLP(3 , [5,4,3] , 0 , \"tanh\" , 0.01 , 500)\n",
        "p.fit(X_train,Y_train)\n",
        "predictions = p.predict(X_test)\n",
        "\n",
        "y = Y_test.to_numpy()\n",
        "predictions = np.array(predictions)\n",
        "print(\"***************************************************\")\n",
        "print(f\"Accuracy: {accuracy(y,predictions)}\")\n",
        "print(\"***************************************************\")\n",
        "\n",
        "y_t = np.apply_along_axis(arg_max_value_func, 1, y)\n",
        "p_t = np.apply_along_axis(arg_max_value_func, 1, predictions)\n",
        "\n",
        "ConfusionMatrix(y_t, p_t, 'Adelie','Chinstrap','Gentoo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "y2rW4IdAIbXO",
        "outputId": "9b3aa5ff-7d4d-474c-e123-50d86b84eaa9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************************************************\n",
            "Accuracy: 1.0\n",
            "***************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zdh1av7JLE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9lD61hLJLIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}